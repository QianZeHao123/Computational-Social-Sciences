---
title: "CSC Appendix"
author: "Z0195806"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1 Dataset Pre-processing

**Dataset World Values Survey Wave 7 (2017-2022)**

Link: <https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp>

It contains data files and original questionnaire.

I download the dataset from this link and put it in "./data" directory.

## 1.1 Read the data from the RData file

```{r}
current_directory <- getwd()
# print(current_directory)
# actual path = current_directory
setwd(current_directory)
load("./data/WVS_Cross-National_Wave_7_rData_v5_0.rdata")
```

```{r}
data.origin = `WVS_Cross-National_Wave_7_v5_0`
```

```{r}
# Using dim() to get both rows and columns
dimensions <- dim(data.origin)
# Prints c(number_of_rows, number_of_columns)
print(dimensions)
```

## 1.2 Missing Values Handling

```{r}
# Check if it exists missing value
any_missing_values <- any(is.na(data.origin))
# Will print TRUE if there are any NAs, otherwise FALSE
print(any_missing_values)
```

```{r}
# Remove the rows with missing value
data.origin = na.omit(data.origin)
```

```{r}
head(data.origin)
```

## 1.3 Sample the Dataset

The dataset is still too big to analyse after deleting all the missing values, so I decide to randomly sample $\frac{1}{4}$ of it.

```{r}
# Use ceiling to round up to the nearest integer
sample_size <- ceiling(0.25 * nrow(data.origin))
data.sample <-
  data.origin[sample(1:nrow(data.origin),
                    size = sample_size,
                    replace = FALSE), ]
write.csv(data.sample, "./data/data.csv", row.names = FALSE)
```

```{r}
data = read.csv("./data/data.csv")
```
